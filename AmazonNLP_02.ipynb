{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "9ZXvY6U7TITT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3eKWsqAUS5yW"
      },
      "outputs": [],
      "source": [
        "corpus = pd.read_json('data.json')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus.drop(columns=['verified', 'reviewTime', 'reviewerID', 'asin', 'style',\n",
        "       'reviewerName', 'summary', 'unixReviewTime', 'vote',\n",
        "       'image'], inplace=True)"
      ],
      "metadata": {
        "id": "YPwzoPMoTPyP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = pd.DataFrame(corpus)"
      ],
      "metadata": {
        "id": "eJPTq5KXTazf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus.rename(columns={'reviewText':'review', 'overall':'sentiment'}, inplace=True)"
      ],
      "metadata": {
        "id": "XPm9XuluTdYJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "X = corpus.drop('sentiment', axis=1)\n",
        "y = corpus['sentiment']\n",
        "\n",
        "sampling_strategy = {\n",
        "    1: 2500,\n",
        "    2: 2500,\n",
        "    3: 2500,\n",
        "    4: 2500,\n",
        "    5: 2500\n",
        "}\n",
        "\n",
        "rus = RandomUnderSampler(\n",
        "    sampling_strategy=sampling_strategy,\n",
        "    random_state=0\n",
        ")\n",
        "\n",
        "X, y = rus.fit_resample(X, y)\n",
        "\n",
        "corpus = pd.concat([X, y], axis=1)\n",
        "corpus = corpus[corpus['sentiment'] != 3]\n",
        "corpus = corpus.sample(frac=1, random_state=0)\n",
        "corpus.reset_index(drop=True, inplace=True)\n",
        "print(corpus.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Z408R9lTidH",
        "outputId": "5e420ca4-34d7-4506-afe1-d85f8d3ae321"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review  sentiment\n",
            "0                                         Works well          5\n",
            "1  It should be known that I attempted to use thi...          1\n",
            "2  Doesnt fit dash cutout of my dodge properly - ...          1\n",
            "3  Good value for the money.  Exactly as advertis...          4\n",
            "4  The clip needed to install on my car snapped i...          1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import nltk\n",
        "import re\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "ob3FQpyXVTQH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dde1f7e-a36b-45ed-8434-eda36bba1fbd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords_en = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "rMm0k9BF84qe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_sentiment(row):\n",
        "    if int(row['sentiment']) <= 2:\n",
        "        return 0\n",
        "    if int(row['sentiment']) >= 4:\n",
        "        return 1"
      ],
      "metadata": {
        "id": "aurJFTNe9zSU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus['sentiment_label'] = corpus.apply(lambda row: label_sentiment(row), axis=1)"
      ],
      "metadata": {
        "id": "mj8Nzd8U9yvN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(text):\n",
        "  \"\"\"\n",
        "  It drops empty texts, NaN, HTML, URLs, numbers and special caracters.\n",
        "  \"\"\"\n",
        "\n",
        "  if not text or text.lower() in ['none', 'nan']:\n",
        "        return \"\"\n",
        "\n",
        "  text = BeautifulSoup(text, \"html5lib\").get_text()\n",
        "\n",
        "  text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
        "\n",
        "  text = re.sub(r\"[^a-zA-Z]\", \" \", text.lower())\n",
        "\n",
        "  text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "  return text"
      ],
      "metadata": {
        "id": "x3sihAsgOiPP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_lemmatize(text):\n",
        "    \"\"\"\n",
        "    Tokenize, drops stopwords and lemamatize.\n",
        "    \"\"\"\n",
        "\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "\n",
        "    tokens = [word for word in tokens if word not in stopwords_en]\n",
        "\n",
        "    lemas = []\n",
        "    for word, tag in nltk.pos_tag(tokens):\n",
        "\n",
        "        if tag.startswith('J'):\n",
        "            pos = 'a'\n",
        "        elif tag.startswith('V'):\n",
        "            pos = 'v'\n",
        "        elif tag.startswith('N'):\n",
        "            pos = 'n'\n",
        "        elif tag.startswith('R'):\n",
        "            pos = 'r'\n",
        "        else:\n",
        "            pos = 'n'\n",
        "\n",
        "        lemas.append(lemmatizer.lemmatize(word, pos=pos))\n",
        "\n",
        "    return \" \".join(lemas)"
      ],
      "metadata": {
        "id": "IsiAlplfN6MA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing_main(review_text):\n",
        "    \"\"\"\n",
        "    Main function of the full pipeline.\n",
        "    \"\"\"\n",
        "    text_processed = preprocessing(review_text)\n",
        "    text_final = tokenize_lemmatize(text_processed)\n",
        "\n",
        "    return text_final"
      ],
      "metadata": {
        "id": "tSw5n2YROH9s"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_mod = corpus.copy()\n",
        "corpus_mod['review_processed'] = corpus_mod['review'].apply(preprocessing_main)"
      ],
      "metadata": {
        "id": "jAfXgyyPONrl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Original review: {}'.format(corpus_mod['review'][1]))\n",
        "print('Processed review: {}'.format(corpus_mod[\"review_processed\"][1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XV-SmQFCU_DW",
        "outputId": "dfa6ac98-39bb-4ba0-c34f-7ad49b1a80c5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original review: It should be known that I attempted to use this on a Honda Civic (D16Y7) The off level jaws made it impossible to grab valve springs. Apparently they are that way to make it easier to grab into springs, but it didn't work for me.  Also, as the tool is tightened to compress the spring, the slider (silver in the picture), moves down , spreading the jaws apart, releasing the spring. All in all, I tried this and immediately sent it back. I had better luck with a 3/8\" box end wrench and pushing the springs into place by hand. Not something I advise, but that worked while this tool didn't.\n",
            "Processed review: know attempted use honda civic level jaw make impossible grab valve spring apparently way make easy grab spring work also tool tighten compress spring slider silver picture move spread jaw apart release spring try immediately send back well luck box end wrench push spring place hand something advise work tool\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_mod.to_json(\"corpus_mod.json\")"
      ],
      "metadata": {
        "id": "0RIBrF1DADXv"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}